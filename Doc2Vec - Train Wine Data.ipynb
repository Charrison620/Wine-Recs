{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec, WordEmbeddingSimilarityIndex, KeyedVectors, TfidfModel\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  points  price  \\\n",
       "0  Portugal  This is ripe and fruity, a wine that is smooth...      87   15.0   \n",
       "1        US  Tart and snappy, the flavors of lime flesh and...      87   14.0   \n",
       "2        US  Pineapple rind, lemon pith and orange blossom ...      87   13.0   \n",
       "3        US  Much like the regular bottling from 2012, this...      87   65.0   \n",
       "4     Spain  Blackberry and raspberry aromas show a typical...      87   15.0   \n",
       "\n",
       "         province                                              title  \\\n",
       "0           Douro      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "1          Oregon      Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "2        Michigan  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "3          Oregon  Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "4  Northern Spain  Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...   \n",
       "\n",
       "              variety  \n",
       "0      Portuguese Red  \n",
       "1          Pinot Gris  \n",
       "2            Riesling  \n",
       "3          Pinot Noir  \n",
       "4  Tempranillo-Merlot  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "df = pd.read_csv('winemag-data-130k-v2.csv',index_col = 0, usecols = [0,1,2,4,5,6,11,12])# we are loading tyhe csv file into datasframe\n",
    "df = df.dropna() #dropping the null data from  the dataframe\n",
    "df.drop_duplicates(subset = \"title\", keep='first',inplace=True)  # we are removing the duplicate entries in titles\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#preprocess obvious wine variety substitution to get wine style \n",
    "pair_sub_dict = {'Alsace white blend':'Alsacian Pinot Gris', 'Syrah':'Syrah / Shiraz', 'Bordeaux-style Red Blend':'Bordeaux Blend', \n",
    "                   'Garganega':'Gargenega',  'Madeira Blend':'Madeira', 'Melon':'Melon de Bourgogne', 'Pedro Ximénez':'Pedro Ximenez',\n",
    "                    'Pinot Grigio':'Pinot Gris / Pinot Grigio', 'Zinfandel':'Zinfanadel',\n",
    "                'Shiraz': 'Syrah / Shiraz', 'Touriga': 'Touriga Nacional', 'Garnacha': 'Garnacha Rosado', 'Rosado':'Garnacha Rosado',\n",
    "                'Syrah-Petite Sirah': \"Petite Sirah\", \"Sauvignon-Sémillon\":\"Sémillon\", 'Chardonnay-Albariño':\"Albariño\",\n",
    "                'Vermentino Nero':'Vermentino', 'White Riesling':'Riesling',\"Chardonnay-Riesling\":'Riesling',\"Riesling-Chardonnay\":'Riesling',\n",
    "                'Chenin Blanc-Sauvignon Blanc':'Chenin Blanc', \"Sauvignon Blanc-Chenin Blanc\":'Chenin Blanc', 'Chenin Blanc-Chardonnay':'Chenin Blanc',\n",
    "                'Chenin Blanc-Viognier':'Chenin Blanc', 'Viognier-Gewürztraminer':'Gewürztraminer', 'Pinot Gris-Gewürztraminer':'Gewürztraminer',\n",
    "                'Gewürztraminer-Riesling':'Gewürztraminer', 'White Port': 'Port', 'Tinta Madeira':'Madeira', 'Orange Muscat':'Muscat',\n",
    "                'Muscat Hamburg':'Muscat', 'Muscat Canelli':'Muscat', \"Muscat d'Alexandrie\":'Muscat', 'Valvin Muscat':'Muscat', 'Muscat Blanc à Petits Grains':'Muscat',\n",
    "                'Muscat of Alexandria':'Muscat', 'Muscat Blanc':'Muscat'}\n",
    "\n",
    "variety_lst = []  # we are creating a list to keep variety\n",
    "for i in df['variety'].to_list():\n",
    "    if i in pair_sub_dict.keys():\n",
    "        variety_lst.append(pair_sub_dict[i]) # we are validating the word enter is from pair_sub_dict dictionary \n",
    "    else:\n",
    "        variety_lst.append(i)  # we are appending the word from df['variety'] features\n",
    "        \n",
    "df['variety'] = variety_lst  # we are updating the  df['variety']  with the  variety_lst list \n",
    "\n",
    "\n",
    "df.head() # display a sample dataframe from our processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wine_df.csv')  # we are saving our dataframe to wine_df as csv file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a sentence tokenizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentences(descriptions):  # defining a function to tokenized the sentences , it takes the descriptions given by user\n",
    "    tokenized_sentences = []   # creating a list to keep the tokenize sentences\n",
    "    for description in descriptions:   # we are breaking the descriptions enter by user into description and keeping it into description\n",
    "        word_list = [] # creating a list to keep the list of words \n",
    "        description = description.lower()  # converting the description into lower case so that our system could knowledge the word and keeping it into description again\n",
    "        doc = nlp(description) #  we are performing natural language processing of the description of word and keeping it into doc variable\n",
    "        for word in doc:  # we are taking word by word and iterating word in doc\n",
    "            if (word.is_alpha) and (word.is_stop == False): # we are checking the word whether it is alphabet or is not stop word\n",
    "                word_list.append(word.lemma_) # appending the lemma into the list word list \n",
    "        tokenized_sentences.append(word_list)# appending the sentence based on lemma of word stored word_list list\n",
    "    return tokenized_sentences # returning the tokenized sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Tokenize wine descriptions and add 2-gram and 3-gram phrases to vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentences\n",
    "wine_sentences = get_tokenized_sentences(df[\"description\"].to_list()) # we are using our defined function to tokenize the descriptions and storing it into wine sentences list\n",
    "\n",
    "#build phrases and add to vocab\n",
    "phrases = Phrases(wine_sentences, min_count=1, threshold=2,delimiter = b' ')  # we are splitting the sentences into phrases based on space in the sentences \n",
    "phrases = Phrases(phrases[wine_sentences], min_count=1, threshold=2, delimiter = b' ')\n",
    "\n",
    "ngrams = Phraser(phrases) #Create 2-gram and 3-gram phrases\n",
    "\n",
    "#add phrases to vocab\n",
    "phrased_sentences = []    # we are declaring list to store the phrased sentence\n",
    "for sent in wine_sentences:  # iterating over wine sentences to get each sentence one by one\n",
    "    phrased_sentence = list(set(ngrams[sent]).union(set(sent))) # # combinig ngram sentence and  each sentence together to get pharsed sentence\n",
    "    phrased_sentences.append(phrased_sentence)# again  to get the sentences we appended the pharased sentence together\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_lst, tags=[str(i)]) for i, word_lst in enumerate(phrased_sentences)]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train and save Doc2Vec model on full wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#train and save model on doc2vec vocab in full wine dataset\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.iter)# trainning the data \n",
    "    model.alpha -= 0.0002\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v_wine.model\") # saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use if model is already built\n",
    "model= Doc2Vec.load(\"d2v_wine.model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create individual datasets by style of wine (Bold Red, Medium Red, etc.) determined by the food/wine pairing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build datasets for specific wine styles\n",
    "with open('wine_food_pairing.json', 'r') as f:\n",
    "    food = json.load(f)\n",
    "    \n",
    "lst = []\n",
    "for k,v in food.items(): # finding item in the food json file\n",
    "    lst.append((k,list(v.keys())))\n",
    "\n",
    "Bold_Red_df = df[(df[\"variety\"].isin(lst[0][1]))]# Bold Red \n",
    "Bold_Red_df.reset_index(inplace = True, drop=True)\n",
    "Bold_Red_df.to_csv('Bold_Red_df.csv') # saving to csv file\n",
    "\n",
    "Medium_Red_df = df[(df[\"variety\"].isin(lst[1][1]))]\n",
    "Medium_Red_df.reset_index(inplace = True, drop=True)\n",
    "Medium_Red_df.to_csv('Medium_Red_df.csv')\n",
    "\n",
    "Light_Red_df = df[(df[\"variety\"].isin(lst[2][1]))]\n",
    "Light_Red_df.reset_index(inplace = True, drop=True)\n",
    "Light_Red_df.to_csv('Light_Red_df.csv')\n",
    "\n",
    "Rose_df = df[(df[\"variety\"].isin(lst[3][1]))]\n",
    "Rose_df.reset_index(inplace = True, drop=True)\n",
    "Rose_df.to_csv('Rose_df.csv')\n",
    "\n",
    "Rich_White_df = df[(df[\"variety\"].isin(lst[4][1]))]\n",
    "Rich_White_df.reset_index(inplace = True, drop=True)\n",
    "Rich_White_df.to_csv('Rich_White_df.csv')\n",
    "\n",
    "Light_White_df = df[(df[\"variety\"].isin(lst[5][1]))]\n",
    "Light_White_df.reset_index(inplace = True, drop=True)\n",
    "Light_White_df.to_csv('Light_White_df.csv')\n",
    "\n",
    "Sweet_White_df = df[(df[\"variety\"].isin(lst[6][1]))]\n",
    "Sweet_White_df.reset_index(inplace = True, drop=True)\n",
    "Sweet_White_df.to_csv('Sweet_White_df.csv')\n",
    "\n",
    "Dessert_df = df[(df[\"variety\"].isin(lst[7][1]))]\n",
    "Dessert_df.reset_index(inplace = True, drop=True)\n",
    "Dessert_df.to_csv('Dessert_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Tokenize the descriptions in each of the separate wine style datasets in order to build separate TF-IDF models for each style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build initial tokenized sentences with spacy\n",
    "Bold_Red_sentences = get_tokenized_sentences(Bold_Red_df[\"description\"].to_list())\n",
    "Medium_Red_sentences = get_tokenized_sentences(Medium_Red_df[\"description\"].to_list())\n",
    "Light_Red_sentences = get_tokenized_sentences(Light_Red_df[\"description\"].to_list())\n",
    "Rose_sentences = get_tokenized_sentences(Rose_df[\"description\"].to_list())\n",
    "Rich_White_sentences = get_tokenized_sentences(Rich_White_df[\"description\"].to_list())\n",
    "Light_White_sentences = get_tokenized_sentences(Light_White_df[\"description\"].to_list())\n",
    "Sweet_White_sentences = get_tokenized_sentences(Sweet_White_df[\"description\"].to_list())\n",
    "Dessert_sentences = get_tokenized_sentences(Dessert_df[\"description\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case the tokenized_sentences are needed in the future\n",
    "sentence_list = [Bold_Red_sentences, Medium_Red_sentences, Light_Red_sentences, Rose_sentences,\n",
    "                Rich_White_sentences, Light_White_sentences, Sweet_White_sentences, Dessert_sentences]\n",
    "\n",
    "sentence_string_list = ['Bold_Red_sentences', 'Medium_Red_sentences', 'Light_Red_sentences', 'Rose_sentences',\n",
    "                'Rich_White_sentences', 'Light_White_sentences', 'Sweet_White_sentences', 'Dessert_sentences']\n",
    "\n",
    "for a, b in zip(sentence_list, sentence_string_list):\n",
    "    with open(f'{b}.json', 'w') as f:\n",
    "        json.dump(a, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Build separate TF-IDF models for each style. Save dictionary and similarity index for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_similarity_builder(style_sentences, style_name):\n",
    "    phrases = Phrases(style_sentences, min_count=1, threshold=2,delimiter = b' ')\n",
    "    phrases = Phrases(phrases[style_sentences], min_count=1, threshold=2, delimiter = b' ')\n",
    "\n",
    "    ngrams = Phraser(phrases) #Create 2-gram and 3-gram phrases\n",
    "\n",
    "    phrased_sentences = []\n",
    "    for sent in style_sentences:\n",
    "        phrased_sentence = list(set(ngrams[sent]).union(set(sent)))\n",
    "        phrased_sentences.append(phrased_sentence)\n",
    "\n",
    "    #create TFIDF\n",
    "    dct = Dictionary(phrased_sentences) \n",
    "    corpus = [dct.doc2bow(sentence) for sentence in phrased_sentences]\n",
    "\n",
    "    tfidf_model = TfidfModel(corpus) #tfidf\n",
    "\n",
    "    word_vectors = model.wv #word vectors trained on the doc2vec model\n",
    "\n",
    "\n",
    "    #TFIDF with weighted word vectors on pre-defined library \n",
    "    sim_matrix = word_vectors.similarity_matrix(dictionary = dct, tfidf = tfidf_model, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "    #uses cosine similarity on pre-defined library for retrieval\n",
    "    doc_sim_index = SoftCosineSimilarity(corpus, sim_matrix) \n",
    "\n",
    "    dct.save(f'{style_name}_dct.model')\n",
    "    doc_sim_index.save(f'{style_name}_sim_index.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "C:\\Users\\charr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n"
     ]
    }
   ],
   "source": [
    "#build initial tokenized sentences with spacy\n",
    "sentence_list = [wine_sentences, Bold_Red_sentences, Medium_Red_sentences, Light_Red_sentences, Rose_sentences, \n",
    "                 Rich_White_sentences, Light_White_sentences, Sweet_White_sentences, Dessert_sentences]\n",
    "\n",
    "style_name_list = ['wine', 'Bold_Red', 'Medium_Red', 'Light_Red', 'Rose', \n",
    "                 'Rich_White', 'Light_White', 'Sweet_White', 'Dessert']\n",
    "\n",
    "\n",
    "for style_sentences, style_name in zip(sentence_list, style_name_list):\n",
    "    doc_similarity_builder(style_sentences, style_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that each of the TFIDF models are built we can begin to build the function that returns wine recommendations based on your preferences and food choices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
